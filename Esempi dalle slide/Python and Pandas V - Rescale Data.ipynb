{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.40000000e+00,   7.00000000e-01,   0.00000000e+00,\n",
       "          1.90000000e+00,   7.60000000e-02,   1.10000000e+01,\n",
       "          3.40000000e+01,   9.97800000e-01,   3.51000000e+00,\n",
       "          5.60000000e-01,   9.40000000e+00],\n",
       "       [  7.80000000e+00,   8.80000000e-01,   0.00000000e+00,\n",
       "          2.60000000e+00,   9.80000000e-02,   2.50000000e+01,\n",
       "          6.70000000e+01,   9.96800000e-01,   3.20000000e+00,\n",
       "          6.80000000e-01,   9.80000000e+00],\n",
       "       [  7.80000000e+00,   7.60000000e-01,   4.00000000e-02,\n",
       "          2.30000000e+00,   9.20000000e-02,   1.50000000e+01,\n",
       "          5.40000000e+01,   9.97000000e-01,   3.26000000e+00,\n",
       "          6.50000000e-01,   9.80000000e+00],\n",
       "       [  1.12000000e+01,   2.80000000e-01,   5.60000000e-01,\n",
       "          1.90000000e+00,   7.50000000e-02,   1.70000000e+01,\n",
       "          6.00000000e+01,   9.98000000e-01,   3.16000000e+00,\n",
       "          5.80000000e-01,   9.80000000e+00],\n",
       "       [  7.40000000e+00,   7.00000000e-01,   0.00000000e+00,\n",
       "          1.90000000e+00,   7.60000000e-02,   1.10000000e+01,\n",
       "          3.40000000e+01,   9.97800000e-01,   3.51000000e+00,\n",
       "          5.60000000e-01,   9.40000000e+00]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "PREPARE YOUR DATA FOR MACHINE LEARNING\n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "data = pd.read_csv('datasets/winequality-red.csv', sep = ';')\n",
    "\n",
    "array = data.values\n",
    "\n",
    "X = array[:, :-1]\n",
    "Y = array[:, -1]\n",
    "X[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 13.717  15.959  10.     11.027  11.603  12.113  11.484  18.513  19.094\n",
      "   12.066  12.308]\n",
      " [ 14.248  17.808  10.     11.747  12.154  15.07   13.233  17.412  15.433\n",
      "   13.144  13.231]\n",
      " [ 14.248  16.575  10.6    11.438  12.003  12.958  12.544  17.632  16.142\n",
      "   12.874  13.231]\n",
      " [ 18.761  11.644  18.4    11.027  11.578  13.38   12.862  18.733  14.961\n",
      "   12.246  13.231]\n",
      " [ 13.717  15.959  10.     11.027  11.603  12.113  11.484  18.513  19.094\n",
      "   12.066  12.308]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "class sklearn.preprocessing.MinMaxScaler(feature_range=(0, 1), copy=True)\n",
    "    Transforms features by scaling each feature to a given range.\n",
    "    \n",
    "    This estimator scales and translates each feature individually such that it is\n",
    "    in the given range on the training set, i.e. between zero and one.\n",
    "\n",
    "Parameters:\n",
    "    - feature_range : tuple (min, max), default=(0, 1)\n",
    "        Desired range of transformed data.\n",
    "    - copy : boolean, optional, default True\n",
    "        Set to False to perform inplace row normalization and avoid a copy \n",
    "        (if the input is already a numpy array).\n",
    "        \n",
    "------------------------------------\n",
    "Methods\n",
    "    - fit(X[, y]) : Compute the minimum and maximum to be used for later scaling.\n",
    "    - fit_transform(X[, y]) : Fit to data, then transform it.\n",
    "    - get_params([deep]) _ Get parameters for this estimator.\n",
    "    - inverse_transform(X) : Undo the scaling of X according to feature_range.\n",
    "    - partial_fit(X[, y]) : Online computation of min and max on X for later scaling.\n",
    "    - set_params(**params) : Set the parameters of this estimator.\n",
    "    - transform(X) : Scaling features of X according to feature_range.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(10,25))\n",
    "rescaledX = scaler.fit_transform(X)\n",
    "# Summarize transformed data\n",
    "numpy.set_printoptions(precision=3)\n",
    "print(rescaledX[0:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.528  0.962 -1.391 -0.453 -0.244 -0.466 -0.379  0.558  1.289 -0.579\n",
      "  -0.96 ]\n",
      " [-0.299  1.967 -1.391  0.043  0.224  0.873  0.624  0.028 -0.72   0.129\n",
      "  -0.585]\n",
      " [-0.299  1.297 -1.186 -0.169  0.096 -0.084  0.229  0.134 -0.331 -0.048\n",
      "  -0.585]\n",
      " [ 1.655 -1.384  1.484 -0.453 -0.265  0.108  0.412  0.664 -0.979 -0.461\n",
      "  -0.585]\n",
      " [-0.528  0.962 -1.391 -0.453 -0.244 -0.466 -0.379  0.558  1.289 -0.579\n",
      "  -0.96 ]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    class sklearn.preprocessing.StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "    \n",
    "    Standardize features by removing the mean and scaling to unit variance\n",
    "    \n",
    "    Centering and scaling happen independently on each feature by computing the relevant \n",
    "    statistics on the samples in the training set. Mean and standard deviation are then stored \n",
    "    to be used on later data using the transform method.\n",
    "    \n",
    "    Standardization of a dataset is a common requirement for many machine learning estimators: \n",
    "    they might behave badly if the individual feature do not more or less look like standard \n",
    "    normally distributed data (e.g. Gaussian with 0 mean and unit variance).\n",
    "    \n",
    "    For instance many elements used in the objective function of a learning algorithm (such as the\n",
    "    RBF kernel of Support Vector Machines or the L1 and L2 regularizers of linear models) assume that\n",
    "    all features are centered around 0 and have variance in the same order. If a feature has a variance \n",
    "    that is orders of magnitude larger that others, it might dominate the objective function and make \n",
    "    the estimator unable to learn from other features correctly as expected.\n",
    "    \n",
    "    This scaler can also be applied to sparse CSR or CSC matrices by passing with_mean=False \n",
    "    to avoid breaking the sparsity structure of the data.\n",
    "\n",
    "Parameters:\n",
    "    - copy : boolean, optional, default True\n",
    "        If False, try to avoid a copy and do inplace scaling instead. This is not guaranteed to \n",
    "        always work inplace; e.g. if the data is not a NumPy array or scipy.sparse CSR matrix, a \n",
    "        copy may still be returned.\n",
    "    - with_mean : boolean, True by default\n",
    "        If True, center the data before scaling. This does not work (and will raise an exception)\n",
    "        when attempted on sparse matrices, because centering them entails building a dense matrix which \n",
    "        in common use cases is likely to be too large to fit in memory.\n",
    "    - with_std : boolean, True by default\n",
    "        If True, scale the data to unit variance (or equivalently, unit standard deviation).\n",
    "\"\"\"\n",
    "\n",
    "scaler = StandardScaler().fit(X)\n",
    "rescaled_X = scaler.transform(X)\n",
    "print(rescaled_X[0:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.]\n",
      " [ 1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "class sklearn.preprocessing.Binarizer(threshold=0.0, copy=True)[source]\n",
    "    \n",
    "    Binarize data (set feature values to 0 or 1) according to a threshold\n",
    " \n",
    "    Values greater than the threshold map to 1, while values less than or equal to the\n",
    "    threshold map to 0. With the default threshold of 0, only positive values map to 1.\n",
    "\n",
    "    Binarization is a common operation on text count data where the analyst can decide to only \n",
    "    consider the presence or absence of a feature rather than a quantified number of occurrences for instance.\n",
    "    \n",
    "    It can also be used as a pre-processing step for estimators that consider boolean random variables \n",
    "    (e.g. modelled using the Bernoulli distribution in a Bayesian setting).\n",
    "\n",
    "Parameters:\n",
    "    - threshold : float, optional (0.0 by default)\n",
    "        Feature values below or equal to this are replaced by 0, above it by 1. Threshold \n",
    "        may not be less than 0 for operations on sparse matrices.\n",
    "    - copy : boolean, optional, default True\n",
    "    set to False to perform inplace binarization and avoid a copy (if the input is already a \n",
    "    numpy array or a scipy.sparse CSR matrix).\n",
    "\"\"\"\n",
    "\n",
    "binarizer = Binarizer(threshold = 3.4).fit(X)\n",
    "binaryX = binarizer.transform(X)\n",
    "print(binaryX[0:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
